{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "from tensorflow.python.tools import optimize_for_inference_lib\n",
    "\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD,RMSprop,adam\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "import theano\n",
    "from PIL import Image\n",
    "from numpy import *\n",
    "# SKLEARN\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "img_rows , img_cols = 128 , 128\n",
    "\n",
    "path1= 'C:\\\\Users\\\\User\\\\Desktop\\\\PycharmProjects\\\\images'\n",
    "path2= 'C:\\\\Users\\\\User\\\\Desktop\\\\PycharmProjects\\\\images-resized'\n",
    "\n",
    "listing = os.listdir(path1)\n",
    "\n",
    "num_samples =size(listing)\n",
    "print(num_samples)\n",
    "\n",
    "for file in listing:\n",
    "    im= Image.open(path1 + '\\\\' + file)\n",
    "    img = im.resize ((img_rows,img_cols))\n",
    "    gray = img.convert('L')\n",
    "    \n",
    "    gray.save(path2 + '\\\\' + file, \"JPEG\" )\n",
    "\n",
    "imlist= os.listdir(path2)\n",
    "im1 =array(Image.open('C:\\\\Users\\\\User\\\\Desktop\\\\PycharmProjects\\\\images-resized' + '\\\\' + imlist[0]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 1]\n"
     ]
    }
   ],
   "source": [
    "immatrix=array ([array(Image.open('C:\\\\Users\\\\User\\\\Desktop\\\\PycharmProjects\\\\images-resized' + '\\\\' + im2)).flatten() \n",
    "                    for im2 in imlist] ,'f')\n",
    "       \n",
    "m,n = immatrix.shape[0:2]\n",
    "\n",
    "label = np.ones((num_samples,), dtype = int64 )\n",
    "label[0:10]=0\n",
    "label[11:40]=1\n",
    "label[41:70]=2\n",
    "label[71:90]=3\n",
    "print(label)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91, 16384)\n",
      "(91,)\n"
     ]
    }
   ],
   "source": [
    "# Number of colour channels for the images: 1 channel for gray-scale.\n",
    "#https://en.wikipedia.org/wiki/Channel_(digital_image)\n",
    "#channels mean number of primary colors\n",
    "data,Label = shuffle(immatrix,label,random_state=2)\n",
    "train_data = [data,Label]\n",
    "\n",
    "\n",
    "plt.imshow(immatrix[16].reshape(img_rows,img_cols))\n",
    "plt.imshow(immatrix[16].reshape(img_rows,img_cols),cmap='gray')\n",
    "print (train_data[0].shape)\n",
    "print (train_data[1].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (72, 1, 128, 128)\n",
      "72 train samples\n",
      "19 test samples\n",
      "label :  [ 0.  1.  0.  0.]\n",
      "[[ 192.  193.  191. ...,  213.  213.  215.]\n",
      " [ 197.  197.  197. ...,  190.  190.  190.]\n",
      " [ 255.  255.  255. ...,  254.  254.  254.]\n",
      " ..., \n",
      " [ 200.  198.  199. ...,  194.  194.  194.]\n",
      " [ 201.  201.  201. ...,  194.  194.  194.]\n",
      " [ 254.  254.  254. ...,  255.  255.  255.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convolutional Layer 1.\n",
    "#When dealing with high-dimensional inputs such as images, \n",
    "#it is impractical to connect neurons to all neurons in the previous volume. \n",
    "#Instead, we will connect each neuron to only a local region of the input volume. \n",
    "#The spatial extent of this connectivity is a hyperparameter called the receptive field \n",
    "#of the neuron (equivalently this is the filter size). \n",
    "#smaller size than input\n",
    "\n",
    "#batch_size to train\n",
    "batch_size = 64\n",
    "# number of output classes\n",
    "nb_classes = 4\n",
    "# number of epochs to train\n",
    "nb_epoch = 20\n",
    "\n",
    "\n",
    "# number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# size of pooling area for max pooling\n",
    "nb_pool = 2\n",
    "# convolution filter size\n",
    "nb_conv = 3\n",
    "\n",
    "(X,y) =(train_data[0],train_data[1])\n",
    "\n",
    "\n",
    "\n",
    "#split X ,y into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "#\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "i = 16\n",
    "plt.imshow(X_train[i, 0], interpolation='nearest')\n",
    "print(\"label : \", Y_train[i,:])\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##preprocessing\n",
    "# \n",
    "\n",
    "train_generator = datagen.flow_from_directory(X_train,\n",
    "                                             target_size=(128,128),\n",
    "                                             batch_size=batch_size,\n",
    "                                             class_mode=Y_train)\n",
    "\n",
    "validation_generator = datagen.flow_from_directory(X_test,\n",
    "                                                  target_size=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=[128, 128,..., activation=\"relu\", padding=\"same\")`\n",
      "  \n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  import sys\n",
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), activation=\"relu\")`\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_shape=[128,128,1]\n",
    "\t\t\t\t\t\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(32, 3,3,border_mode='same',input_shape=input_shape,activation='relu'))\n",
    "model.add(Convolution2D(32, 3, 3,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Convolution2D(64, 3, 3,activation='relu'))\n",
    "#model.add(Convolution2D(64, 3, 3))\n",
    "#model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64,activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes,activation='softmax'))\n",
    "\n",
    "#sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "#model.compile(loss='categorical_crossentropy', optimizer=sgd,metrics=[\"accuracy\"])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train(model, X_train, Y_train, X_test, Y_test):\n",
    "   \n",
    "    model.fit(X_train, Y_train, \\\n",
    "              batch_size=batch_size, \\\n",
    "              epochs=nb_epoch, \\\n",
    "              verbose=1, \\\n",
    "              validation_data=(X_test, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
